#!/bin/bash

# BoostSRL-AutoGrader v0.01
# Written by Alexander L. Hayes
# hayesall@indiana.edu
# Last updated: 4/20/2017

# Sample call:
# $ bash autograder.sh [JAR-FILE]

RED='\033[0;31m'
LIGHTGREEN='\033[1;32m'
YELLOW='\033[1;33m'
LIGHTBLUE='\033[1;34m'
NC='\033[0m'
BOLD='\e[1m'
ITAL='\e[3m'
UNDL='\e[4m'

NUMBEROFERRORS=0

function name {
    printf "${BOLD}NAME${NC}\n"
    printf "       autograder - AutoGrader: check for consistency between versions of BoostSRL.\n\n"
}

function synopsis {
    printf "${BOLD}SYNOPSIS${NC}\n"
    printf "       bash autograder.sh [${UNDL}OPTIONS${NC}]... [${UNDL}JAR${NC}]\n\n"
}

function hlp {
    name; synopsis;
}

if [[ ! -z $1 ]]; then
    JAR=$1
    if [[ ! -e $JAR ]]; then
	printf "${RED}A jar file was specified, but could not be found, here is the help menu:${NC}\n"
    fi
else
    printf "${RED}A jar file was not specified, here is the help menu:${NC}\n"
    hlp
    exit 2
fi

# add an additional parameter to compare.py for changing the sensitivity threshold

if [[ -e Results.txt ]]; then
    rm -f Results.txt
fi

#rm -rf datasets/Father/models/*

EPOCHS=2
# a hack to create something similar to dictionaries

# Stretched out:
#"SET='Father';
#TRAIN='-train datasets/Father/train/ -target father';
#TEST='-model datasets/Father/train/models -test datasets/Father/test/ -target father';
#TARGET='father';
#TREES='-trees 25'"

DATASETS=(
    "SET='Father'; TRAIN='-train datasets/Father/train/ -target father'; TEST='-model datasets/Father/train/models/ -test datasets/Father/test/ -target father'; TARGET='father'; TREES='-trees 10'"
    # all of Toy-Cancer seems to be broken.
    #"SET='Toy-Cancer'; TRAIN='-train datasets/Toy-Cancer/train/ -target cancer'; TEST='-model datasets/Toy-Cancer/train/models/ -test datasets/Toy-Cancer/test/ -target cancer'; TARGET='cancer'"
)

for ((e=0; e<${EPOCHS}; e++)); do
    echo -e "------\nEpoch $e\n" >> Results.txt
    
    for ((d=0; d<${#DATASETS[*]}; d++)); do
	eval ${DATASETS[d]}
	echo $SET
	echo $TRAIN
	echo $TEST
	echo $TARGET
	echo $TREES

	NAMES=(
	    "RDN-Boost"
	    "RDN-Boost with -noBoost"
	    "Soft Margin with alpha(0.5) and beta(-2)"
	    "Soft Margin with alpha(2) and beta(-10)"
	    "MLN-Boost"
	    "MLN-Boost with -mlnClause"
	    "LSTree Boosting Regression"
	)
	
	TRAINS=(
	    "java -jar $JAR -l $TRAIN $TREES"
	    "java -jar $JAR -l -noBoost $TRAIN"
	    "java -jar $JAR -l -softm -alpha 0.5 -beta -2 $TRAIN $TREES"
	    "java -jar $JAR -l -softm -alpha 2 -beta -10 $TRAIN $TREES"
	    "java -jar $JAR -l -mln $TRAIN $TREES"
	    "java -jar $JAR -l -mln -mlnClause $TRAIN $TREES"
	    "java -jar $JAR -l -reg $TRAIN $TREES"
	)
	
	TESTS=(
	    "java -jar $JAR -i $TEST $TREES"
	    "java -jar $JAR -i $TEST"
	    "java -jar $JAR -i $TEST $TREES"
	    "java -jar $JAR -i $TEST $TREES"
	    "java -jar $JAR -i $TEST $TREES"
	    "java -jar $JAR -i $TEST $TREES"
	    "java -jar $JAR -i $TEST $TREES"
	)
	
	COMPARES=(
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_rdn.db"
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_rdn_noboost.db"
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_softmA0.5B-2.db"
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_softmA2B-10.db"
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_mln.db"
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_mln_mlnClause.db"
	    "python compare.py datasets/$SET/test/results_$TARGET.db static/$SET/results_regression.db"
	)
	
	rm -rf "datasets/$SET/train/models/*"
	
	for ((i=0; i<${#NAMES[*]}; i++)); do
	    printf "${LIGHTBLUE}Testing ${NAMES[i]}...${NC}\n"
	    ${TRAINS[i]} > trainlog.txt
	    #echo ${TRAINS[i]}
	    echo "${SET}: ${NAMES[i]}" >> Results.txt
	    #echo ${TRAINS[i]} >> Results.txt
	    if [[ "$?" = 0 ]]; then
		printf " - ${LIGHTGREEN}Training completed without errors.${NC}\n"
		${TESTS[i]} > testlog.txt
		#echo ${TESTS[i]}
		#echo ${TESTS[i]} >> Results.txt
		if [[ "$?" = 0 ]]; then
		    printf " - ${LIGHTGREEN}Testing completed without errors.${NC}\n"
		    ${COMPARES[i]} >> Results.txt
		else
		    printf " - ${RED}Errors encountered during testing for ${NAMES[i]}.${NC}\n"
		    echo "Errors encountered during testing for ${NAMES[i]}." >> Results.txt
		fi
	    else
		printf " - ${RED}Errors encountered during training for ${NAMES[i]}.${NC}\n"
		echo "Errors encountered during training for ${NAMES[i]}." >> Results.txt
	    fi
	    printf "\n" >> Results.txt
	    printf "\n"
	done
    done
done

rm -f trainlog.txt
rm -f testlog.txt

exit 0

#if [[ -e datasets/Father/test/results_father.db ]]; then
# check if the file is the same as static/Father/results_father.db
#    X=$(md5sum datasets/Father/test/results_father.db | cut -f 1 -d ' ')
#    Y=$(md5sum static/Father/results_father.db | cut -f 1 -d ' ')
#    if [[ "$X" = "$Y" ]]; then
#	printf "${LIGHTGREEN}Success${NC}\n"
#    else
#	printf "${RED}Error, outcome does not match expected outcome.${NC}\n"
#	NUMBEROFERRORS=$((NUMBEROFERRORS+1))
#    fi
#fi
